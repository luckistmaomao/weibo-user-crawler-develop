单机上的爬虫优化

1 反爬取策略：
1.1 抓取频率
同时开启N个线程抓取一个网站，很快就会被对方网站封掉；
抓取的频率也很重要；抓取网站同时不对对方网站造成压力（这是良心做法）
对于一般的抓取而言，10到20秒抓取一次是一个比较保险的频率，也有提出10*t的抓取间隔（t是download时间）比较合理

1.2 使用代理服务器(todo)
参考链接 http://lvyaojia.sinaapp.com/2012/10/python%E7%88%AC%E8%99%AB%E6%80%BB%E7%BB%93/

2 加速数据下载

2.1、gzip/deflate支持(todo)
现在的网页普遍支持gzip压缩，这往往可以解决大量传输时间
以VeryCD的主页为例，未压缩版本247K，压缩了以后45K，为原来的1/5。这就意味着抓取速度会快5倍。
参考下面链接：
http://woodpecker.org.cn/diveintopython3/http-web-services.html

2.2 爬虫假死

多进程的话，可以没隔一段时间给一个监控进程发信号
当监控进程收不到信号的时候就说明那个程序死了，然后强制终止爬虫进程，再开启一个新爬虫进程继续。

2.3 判断瓶颈在哪里(todo)

2.3.1 网络io问题 --- 带宽问题；

2.3.2 磁盘io考虑使用分布式-- 硬件问题

2.3.3 cpu占用不饱和，可以考虑多线程、异步等
	2.2.3.1 异步可以考虑使用tornado的异步客户端。
	http://www.tornadoweb.org/en/stable/
	2.2.3.2 多线程策略

2.4 对付重复的网页(todo)

重复抓取会浪费资源。判断抓不抓，抓了后存不存，并且这个缓存需要快速读写。

常见的做法有bloomfilter、相似度聚合、分类海明距离判断。

2.5 监控管理(todo)

如果对方服务器宕机、网页改版、更换地址等我们需要第一时间知道，这时监控系统就起到出现了问题及时发现并通知联系人。

2.5.1 日志处理（todo）
将抓取失败的信息 写入日志中

2.6 待考虑因素

参考链接：
http://www.pythonclub.org/python-network-application/observer-spider


